X_testm[p+2,Lag2]<-ptest[p,i]
}
}
}
else
{
#Treinando e prevendo cada componente com cada modelo
X_trainm<-rbind(train[,-1],Aux_1);
X_testm <-rbind(test[,-1],Aux_1);
colnames(X_trainm)=colnames(X_train)
colnames(X_testm) =colnames(X_test)
h<-Horizon
#Train
for(p in 1:cut)
{
if(p%%h !=1) #Sempre reinicia na divisão de resto 1-->Multiplos de h+1
{
ptrain[p,i]<-round(predict(Models[[k]], as.data.frame(t(X_trainm[p,]))))
X_trainm[p+1,Lag1]<-ptrain[p,i]
X_trainm[p+2,Lag2]<-ptrain[p,i]
X_trainm[p+3,Lag3]<-ptrain[p,i]
X_trainm[p+4,Lag4]<-ptrain[p,i]
X_trainm[p+5,Lag5]<-ptrain[p,i]
}
else
{
X_trainm[p:(n-cut),]<-X_train[p:(n-cut),]
ptrain[p,i]       <-round(predict(Models[[k]], as.data.frame(t(X_trainm[p,]))))
X_trainm[p+1,Lag1]<-ptrain[p,i]
X_trainm[p+2,Lag2]<-ptrain[p,i]
X_trainm[p+3,Lag3]<-ptrain[p,i]
X_trainm[p+4,Lag4]<-ptrain[p,i]
X_trainm[p+5,Lag5]<-ptrain[p,i]
}
}
#Test
for(p in 1:(n-cut))
{
if(p%%h !=1)
{
ptest[p,i]<-round(predict(Models[[k]], as.data.frame(t(X_testm[p,]))))
X_testm[p+1,Lag1]<-ptest[p,i]
X_testm[p+2,Lag2]<-ptest[p,i]
X_testm[p+3,Lag3]<-ptest[p,i]
X_testm[p+4,Lag4]<-ptest[p,i]
X_testm[p+5,Lag5]<-ptest[p,i]
}
else
{
X_testm[p:(n-cut),]<-X_test[p:(n-cut),]
ptest[p,i]       <-round(predict(Models[[k]], as.data.frame(t(X_testm[p,]))))
X_testm[p+1,Lag1]<-ptest[p,i]
X_testm[p+2,Lag2]<-ptest[p,i]
X_testm[p+3,Lag3]<-ptest[p,i]
X_testm[p+4,Lag4]<-ptest[p,i]
X_testm[p+5,Lag5]<-ptest[p,i]
}
}
}
}
else
{
predictions_arima<-forecast(Arimas[[a]],h=6)
ptest[,i] <-round(c(predictions_arima$mean))
ptrain[,i] <-round(c(Arimas[[a]]$fitted))
}
#Erros
errorstest[,i] <-round(Y_test-ptest[1:6,i])
errorstrain[,i] <-round(Y_train-ptrain[1:cut,i])
#Metrics in test
criterias<-PM(Y_test,ptest[1:6,i],mean(Y_test))
Metrics[i,]<-c(criterias[,c("RRMSE","MAE","SMAPE")],sd(errorstest[1:6,i]))
#Cada elemento da lista recebera uma combinação de process com control
cat("State:",States[s],"Horizon:",Horizon,
sprintf('RRMSE: %0.3f',Metrics[i,1]),
sprintf('SMAPE: %0.3f',Metrics[i,3]),
sprintf('MAE: %0.3f'  ,Metrics[i,2]),
sprintf('SD: %0.3f'   ,Metrics[i,4]),
'Model:',ifelse(i==6,"Arima",ifelse(i==5,"Stack-ELM",models[i])),
"\n")
k<-k+1
}
a<-a+1
Metrics_States[[s]]  <-Metrics[order(Metrics[,3],decreasing=FALSE),]
Ptrain[[s]]          <-ptrain;
Ptest[[s]]           <-ptest;
Etrain[[s]]          <-errorstrain;
Etest[[s]]           <-errorstest;
}
stopImplicitCluster()
for(s in 1:length(data))           #Variando o conjunto de dados
{
{
Data_state      <-c(Aux_2,data[[s]][,"confirmed"])
#--------------------------Construindo Conjuno-----------------------------#
data_m<-lags(Data_state, n = 5) #n representa o número de lags
colnames(data_m)<-c("Confirmed",paste("Lag",1:5,sep=""))
#----------------------Divisão em treinamento e teste---------------------#
n      <-dim(data_m)[1]    #Número de observações
cut    <-n-6               #Ponto de corte entre treino e teste
ptrain          <-matrix(nrow=cut,ncol=length(models)+2); #Recebe predições 3SA das componentes
ptest           <-matrix(nrow=n-cut,ncol=length(models)+2);  #Recebe predições 3SA das componentes
colnames(ptrain)<-c(models,"GP-Stack","ARIMA");colnames(ptest) <-c(models,"ELM-Stack","ARIMA")
errorstrain          <-matrix(nrow=cut,ncol=length(models)+2); #Recebe predições 3SA das componentes
errorstest          <-matrix(nrow=n-cut,ncol=length(models)+2);  #Recebe predições 3SA das componentes
colnames(errorstrain )<-c(models,"GP-Stack","ARIMA");colnames(errorstest) <-c(models,"ELM-Stack","ARIMA")
fitControl2<- trainControl(method= "cv",number=5,savePredictions="final")
#Train and Test
train  <-data_m[1:cut,];
Y_train<-train[,1];X_train<-train[,-1]
test   <-tail(data_m,n-cut)
Y_test <-test[,1]; X_test <-test[,-1]
#----------------------Divisões para Treinamento----------------------------#
}
#-----------------------Training---------------------------#
for(i in 1:(length(models)+2)) #Aqui está indo de 1 até número de modelos +1 pois tem o stacking
{
options(warn=-1)
if(i != 6)
{
if(i != 5)
{
set.seed(1234)
Models[[k]]<-train(as.data.frame(X_train[1:cut,]),as.vector(Y_train),
method=models[[i]],
preProcess = c("center","scale"), #Processamento Centro e Escala
tuneLength= 4,                    #Número de tipos de parâmetros
trControl = fitControl2,verbose=FALSE)
}
else
{
#Stacking ensemble
modelst <- caretList(as.data.frame(X_train[1:cut,]),as.vector(Y_train),
trControl=fitControl2,
preProcess = c("center","scale"),
methodList=models)
Models[[k]] <-caretStack(modelst,
trControl=fitControl2,
method='gaussprLinear',
preProcess = c("center","scale"),
tuneLength= 5)
}
#-----------------------Salvando Parâmetros--------------------------------#
Params[[k]]<-Models[[k]]$bestTune
}
else
{
Arimas[[a]]<-auto.arima(Y_train)
}
#---------------------------Lags-Names-----------------------------------------#
Lag1<-match("Lag1",colnames(X_test));Lag2<-match("Lag2",colnames(X_test))
Lag3<-match("Lag3",colnames(X_test));Lag4<-match("Lag2",colnames(X_test))
Lag5<-match("Lag3",colnames(X_test))
#------------------Recursive Forecasting for train and test sets-----------
#Aqui, o conjunto de análise é dividido em n conjuntos de h observações. Nesse caso
#A cada 3 predições, é reiniciado o processo de previsão. Caso isso não seja feito,
#as predições continuarão a ser atualizadas e o erro carregado.
#Se desejar h>3, basta tirar fazer H<-HORIZONTE DESEJADO e descomentar
#X_trainm[p+3,Lag3]<-ptrain[p,m] e #X_testm[p+3,Lag3]<-ptest[p,m]
if(i != 6)
{
#Vai colocar as predições em cada coluna
if(Horizon==1)
{
h<-Horizon
#Train
ptrain[1:cut,i]<-round(predict(Models[[k]], X_train[1:cut,]))
#Test
ptest[1:6,i]<-round(predict(Models[[k]],X_test[1:6,]))
}
else if(Horizon==3)
{
h<-Horizon
#Treinando e prevendo cada componente com cada modelo
X_trainm<-rbind(train[,-1],Aux_1);
X_testm <-rbind(test[,-1],Aux_1);
colnames(X_trainm)=colnames(X_train)
colnames(X_testm) =colnames(X_test)
#Train
for(p in 1:cut)
{
if(p%%h !=1) #Sempre reinicia na divisão de resto 1-->Multiplos de h+1
{
ptrain[p,i]<-round(predict(Models[[k]], as.data.frame(t(X_trainm[p,]))))
X_trainm[p+1,Lag1]<-ptrain[p,i]
X_trainm[p+2,Lag2]<-ptrain[p,i]
}
else
{
X_trainm[p:(n-cut),]<-X_train[p:(n-cut),]
ptrain[p,i]       <-round(predict(Models[[k]], as.data.frame(t(X_trainm[p,]))))
X_trainm[p+1,Lag1]<-ptrain[p,i]
X_trainm[p+2,Lag2]<-ptrain[p,i]
}
}
#Test
for(p in 1:(n-cut))
{
if(p%%h !=1)
{
ptest[p,i]<-round(predict(Models[[k]], as.data.frame(t(X_testm[p,]))))
X_testm[p+1,Lag1]<-ptest[p,i]
X_testm[p+2,Lag2]<-ptest[p,i]
}
else
{
X_testm[p:(n-cut),]<-X_test[p:(n-cut),]
ptest[p,i]       <-round(predict(Models[[k]], as.data.frame(t(X_testm[p,]))))
X_testm[p+1,Lag1]<-ptest[p,i]
X_testm[p+2,Lag2]<-ptest[p,i]
}
}
}
else
{
#Treinando e prevendo cada componente com cada modelo
X_trainm<-rbind(train[,-1],Aux_1);
X_testm <-rbind(test[,-1],Aux_1);
colnames(X_trainm)=colnames(X_train)
colnames(X_testm) =colnames(X_test)
h<-Horizon
#Train
for(p in 1:cut)
{
if(p%%h !=1) #Sempre reinicia na divisão de resto 1-->Multiplos de h+1
{
ptrain[p,i]<-round(predict(Models[[k]], as.data.frame(t(X_trainm[p,]))))
X_trainm[p+1,Lag1]<-ptrain[p,i]
X_trainm[p+2,Lag2]<-ptrain[p,i]
X_trainm[p+3,Lag3]<-ptrain[p,i]
X_trainm[p+4,Lag4]<-ptrain[p,i]
X_trainm[p+5,Lag5]<-ptrain[p,i]
}
else
{
X_trainm[p:(n-cut),]<-X_train[p:(n-cut),]
ptrain[p,i]       <-round(predict(Models[[k]], as.data.frame(t(X_trainm[p,]))))
X_trainm[p+1,Lag1]<-ptrain[p,i]
X_trainm[p+2,Lag2]<-ptrain[p,i]
X_trainm[p+3,Lag3]<-ptrain[p,i]
X_trainm[p+4,Lag4]<-ptrain[p,i]
X_trainm[p+5,Lag5]<-ptrain[p,i]
}
}
#Test
for(p in 1:(n-cut))
{
if(p%%h !=1)
{
ptest[p,i]<-round(predict(Models[[k]], as.data.frame(t(X_testm[p,]))))
X_testm[p+1,Lag1]<-ptest[p,i]
X_testm[p+2,Lag2]<-ptest[p,i]
X_testm[p+3,Lag3]<-ptest[p,i]
X_testm[p+4,Lag4]<-ptest[p,i]
X_testm[p+5,Lag5]<-ptest[p,i]
}
else
{
X_testm[p:(n-cut),]<-X_test[p:(n-cut),]
ptest[p,i]       <-round(predict(Models[[k]], as.data.frame(t(X_testm[p,]))))
X_testm[p+1,Lag1]<-ptest[p,i]
X_testm[p+2,Lag2]<-ptest[p,i]
X_testm[p+3,Lag3]<-ptest[p,i]
X_testm[p+4,Lag4]<-ptest[p,i]
X_testm[p+5,Lag5]<-ptest[p,i]
}
}
}
}
else
{
predictions_arima<-forecast(Arimas[[a]],h=6)
ptest[,i] <-round(c(predictions_arima$mean))
ptrain[,i] <-round(c(Arimas[[a]]$fitted))
}
#Erros
errorstest[,i] <-round(Y_test-ptest[1:6,i])
errorstrain[,i] <-round(Y_train-ptrain[1:cut,i])
#Metrics in test
criterias<-PM(Y_test,ptest[1:6,i],mean(Y_test))
Metrics[i,]<-c(criterias[,c("RRMSE","MAE","SMAPE")],sd(errorstest[1:6,i]))
#Cada elemento da lista recebera uma combinação de process com control
cat("State:",States[s],"Horizon:",Horizon,
sprintf('RRMSE: %0.3f',Metrics[i,1]),
sprintf('SMAPE: %0.3f',Metrics[i,3]),
sprintf('MAE: %0.3f'  ,Metrics[i,2]),
sprintf('SD: %0.3f'   ,Metrics[i,4]),
'Model:',ifelse(i==6,"Arima",ifelse(i==5,"Stack-ELM",models[i])),
"\n")
k<-k+1
}
a<-a+1
Metrics_States[[s]]  <-Metrics[order(Metrics[,3],decreasing=FALSE),]
Ptrain[[s]]          <-ptrain;
Ptest[[s]]           <-ptest;
Etrain[[s]]          <-errorstrain;
Etest[[s]]           <-errorstest;
}
stopImplicitCluster()
ncl<-detectCores();ncl
#Registra os clusters a serem utilizados
cl <- makeCluster(ncl-1);registerDoParallel(cl)
for(s in 1:length(data))           #Variando o conjunto de dados
{
{
Data_state      <-c(Aux_2,data[[s]][,"confirmed"])
#--------------------------Construindo Conjuno-----------------------------#
data_m<-lags(Data_state, n = 5) #n representa o número de lags
colnames(data_m)<-c("Confirmed",paste("Lag",1:5,sep=""))
#----------------------Divisão em treinamento e teste---------------------#
n      <-dim(data_m)[1]    #Número de observações
cut    <-n-6               #Ponto de corte entre treino e teste
ptrain          <-matrix(nrow=cut,ncol=length(models)+2); #Recebe predições 3SA das componentes
ptest           <-matrix(nrow=n-cut,ncol=length(models)+2);  #Recebe predições 3SA das componentes
colnames(ptrain)<-c(models,"GP-Stack","ARIMA");colnames(ptest) <-c(models,"ELM-Stack","ARIMA")
errorstrain          <-matrix(nrow=cut,ncol=length(models)+2); #Recebe predições 3SA das componentes
errorstest          <-matrix(nrow=n-cut,ncol=length(models)+2);  #Recebe predições 3SA das componentes
colnames(errorstrain )<-c(models,"GP-Stack","ARIMA");colnames(errorstest) <-c(models,"ELM-Stack","ARIMA")
fitControl2<- trainControl(method= "cv",number=5,savePredictions="final")
#Train and Test
train  <-data_m[1:cut,];
Y_train<-train[,1];X_train<-train[,-1]
test   <-tail(data_m,n-cut)
Y_test <-test[,1]; X_test <-test[,-1]
#----------------------Divisões para Treinamento----------------------------#
}
#-----------------------Training---------------------------#
for(i in 1:(length(models)+2)) #Aqui está indo de 1 até número de modelos +1 pois tem o stacking
{
options(warn=-1)
if(i != 6)
{
if(i != 5)
{
set.seed(1234)
Models[[k]]<-train(as.data.frame(X_train[1:cut,]),as.vector(Y_train),
method=models[[i]],
preProcess = c("center","scale"), #Processamento Centro e Escala
tuneLength= 4,                    #Número de tipos de parâmetros
trControl = fitControl2,verbose=FALSE)
}
else
{
#Stacking ensemble
modelst <- caretList(as.data.frame(X_train[1:cut,]),as.vector(Y_train),
trControl=fitControl2,
preProcess = c("center","scale"),
methodList=models)
Models[[k]] <-caretStack(modelst,
trControl=fitControl2,
method='gaussprLinear',
preProcess = c("center","scale"),
tuneLength= 5)
}
#-----------------------Salvando Parâmetros--------------------------------#
Params[[k]]<-Models[[k]]$bestTune
}
else
{
Arimas[[a]]<-auto.arima(Y_train)
}
#---------------------------Lags-Names-----------------------------------------#
Lag1<-match("Lag1",colnames(X_test));Lag2<-match("Lag2",colnames(X_test))
Lag3<-match("Lag3",colnames(X_test));Lag4<-match("Lag2",colnames(X_test))
Lag5<-match("Lag3",colnames(X_test))
#------------------Recursive Forecasting for train and test sets-----------
#Aqui, o conjunto de análise é dividido em n conjuntos de h observações. Nesse caso
#A cada 3 predições, é reiniciado o processo de previsão. Caso isso não seja feito,
#as predições continuarão a ser atualizadas e o erro carregado.
#Se desejar h>3, basta tirar fazer H<-HORIZONTE DESEJADO e descomentar
#X_trainm[p+3,Lag3]<-ptrain[p,m] e #X_testm[p+3,Lag3]<-ptest[p,m]
if(i != 6)
{
#Vai colocar as predições em cada coluna
if(Horizon==1)
{
h<-Horizon
#Train
ptrain[1:cut,i]<-round(predict(Models[[k]], X_train[1:cut,]))
#Test
ptest[1:6,i]<-round(predict(Models[[k]],X_test[1:6,]))
}
else if(Horizon==3)
{
h<-Horizon
#Treinando e prevendo cada componente com cada modelo
X_trainm<-rbind(train[,-1],Aux_1);
X_testm <-rbind(test[,-1],Aux_1);
colnames(X_trainm)=colnames(X_train)
colnames(X_testm) =colnames(X_test)
#Train
for(p in 1:cut)
{
if(p%%h !=1) #Sempre reinicia na divisão de resto 1-->Multiplos de h+1
{
ptrain[p,i]<-round(predict(Models[[k]], as.data.frame(t(X_trainm[p,]))))
X_trainm[p+1,Lag1]<-ptrain[p,i]
X_trainm[p+2,Lag2]<-ptrain[p,i]
}
else
{
X_trainm[p:(n-cut),]<-X_train[p:(n-cut),]
ptrain[p,i]       <-round(predict(Models[[k]], as.data.frame(t(X_trainm[p,]))))
X_trainm[p+1,Lag1]<-ptrain[p,i]
X_trainm[p+2,Lag2]<-ptrain[p,i]
}
}
#Test
for(p in 1:(n-cut))
{
if(p%%h !=1)
{
ptest[p,i]<-round(predict(Models[[k]], as.data.frame(t(X_testm[p,]))))
X_testm[p+1,Lag1]<-ptest[p,i]
X_testm[p+2,Lag2]<-ptest[p,i]
}
else
{
X_testm[p:(n-cut),]<-X_test[p:(n-cut),]
ptest[p,i]       <-round(predict(Models[[k]], as.data.frame(t(X_testm[p,]))))
X_testm[p+1,Lag1]<-ptest[p,i]
X_testm[p+2,Lag2]<-ptest[p,i]
}
}
}
else
{
#Treinando e prevendo cada componente com cada modelo
X_trainm<-rbind(train[,-1],Aux_1);
X_testm <-rbind(test[,-1],Aux_1);
colnames(X_trainm)=colnames(X_train)
colnames(X_testm) =colnames(X_test)
h<-Horizon
#Train
for(p in 1:cut)
{
if(p%%h !=1) #Sempre reinicia na divisão de resto 1-->Multiplos de h+1
{
ptrain[p,i]<-round(predict(Models[[k]], as.data.frame(t(X_trainm[p,]))))
X_trainm[p+1,Lag1]<-ptrain[p,i]
X_trainm[p+2,Lag2]<-ptrain[p,i]
X_trainm[p+3,Lag3]<-ptrain[p,i]
X_trainm[p+4,Lag4]<-ptrain[p,i]
X_trainm[p+5,Lag5]<-ptrain[p,i]
}
else
{
X_trainm[p:(n-cut),]<-X_train[p:(n-cut),]
ptrain[p,i]       <-round(predict(Models[[k]], as.data.frame(t(X_trainm[p,]))))
X_trainm[p+1,Lag1]<-ptrain[p,i]
X_trainm[p+2,Lag2]<-ptrain[p,i]
X_trainm[p+3,Lag3]<-ptrain[p,i]
X_trainm[p+4,Lag4]<-ptrain[p,i]
X_trainm[p+5,Lag5]<-ptrain[p,i]
}
}
#Test
for(p in 1:(n-cut))
{
if(p%%h !=1)
{
ptest[p,i]<-round(predict(Models[[k]], as.data.frame(t(X_testm[p,]))))
X_testm[p+1,Lag1]<-ptest[p,i]
X_testm[p+2,Lag2]<-ptest[p,i]
X_testm[p+3,Lag3]<-ptest[p,i]
X_testm[p+4,Lag4]<-ptest[p,i]
X_testm[p+5,Lag5]<-ptest[p,i]
}
else
{
X_testm[p:(n-cut),]<-X_test[p:(n-cut),]
ptest[p,i]       <-round(predict(Models[[k]], as.data.frame(t(X_testm[p,]))))
X_testm[p+1,Lag1]<-ptest[p,i]
X_testm[p+2,Lag2]<-ptest[p,i]
X_testm[p+3,Lag3]<-ptest[p,i]
X_testm[p+4,Lag4]<-ptest[p,i]
X_testm[p+5,Lag5]<-ptest[p,i]
}
}
}
}
else
{
predictions_arima<-forecast(Arimas[[a]],h=6)
ptest[,i] <-round(c(predictions_arima$mean))
ptrain[,i] <-round(c(Arimas[[a]]$fitted))
}
#Erros
errorstest[,i] <-round(Y_test-ptest[1:6,i])
errorstrain[,i] <-round(Y_train-ptrain[1:cut,i])
#Metrics in test
criterias<-PM(Y_test,ptest[1:6,i],mean(Y_test))
Metrics[i,]<-c(criterias[,c("RRMSE","MAE","SMAPE")],sd(errorstest[1:6,i]))
#Cada elemento da lista recebera uma combinação de process com control
cat("State:",States[s],"Horizon:",Horizon,
sprintf('RRMSE: %0.3f',Metrics[i,1]),
sprintf('SMAPE: %0.3f',Metrics[i,3]),
sprintf('MAE: %0.3f'  ,Metrics[i,2]),
sprintf('SD: %0.3f'   ,Metrics[i,4]),
'Model:',ifelse(i==6,"Arima",ifelse(i==5,"Stack-ELM",models[i])),
"\n")
k<-k+1
}
a<-a+1
Metrics_States[[s]]  <-Metrics[order(Metrics[,3],decreasing=FALSE),]
Ptrain[[s]]          <-ptrain;
Ptest[[s]]           <-ptest;
Etrain[[s]]          <-errorstrain;
Etest[[s]]           <-errorstest;
}
Metrics
Metrics_States
